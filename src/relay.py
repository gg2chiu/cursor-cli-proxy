import asyncio
import subprocess
import json
import os
import re
from pathlib import Path
from typing import List, Optional, Dict
from loguru import logger
from src.config import config
from src.models import Message

class SlashCommandLoader:
    """è¼‰å…¥å’Œå±•é–‹ .cursor/commands å’Œ .claude/commands ä¸­çš„è‡ªå®šç¾© slash æŒ‡ä»¤"""
    
    def __init__(self, workspace_dir: Optional[str] = None):
        self.workspace_dir = workspace_dir or os.getcwd()
        self.commands: Dict[str, str] = {}
        self._load_commands()
    
    def _load_commands(self):
        """æŒ‰å„ªå…ˆé †åºè¼‰å…¥æŒ‡ä»¤ï¼šteam < workspace-claude < workspace-cursor < user-claude < user-cursor"""
        # å„ªå…ˆé †åºå¾ä½åˆ°é«˜
        search_paths = [
            # Workspace commands (lower priority)
            Path(self.workspace_dir) / ".claude" / "commands",
            Path(self.workspace_dir) / ".cursor" / "commands",
            # User commands (higher priority, override workspace)
            Path.home() / ".claude" / "commands",
            Path.home() / ".cursor" / "commands",
        ]
        
        for commands_dir in search_paths:
            if commands_dir.exists() and commands_dir.is_dir():
                self._load_from_directory(commands_dir)
    
    def _load_from_directory(self, directory: Path):
        """å¾æŒ‡å®šç›®éŒ„è¼‰å…¥æ‰€æœ‰ .md æª”æ¡ˆä½œç‚ºæŒ‡ä»¤"""
        try:
            for md_file in directory.glob("*.md"):
                command_id = md_file.stem  # æª”åï¼ˆä¸å« .mdï¼‰
                try:
                    content = md_file.read_text(encoding="utf-8").strip()
                    if content:
                        self.commands[command_id] = content
                        logger.debug(f"Loaded slash command: /{command_id} from {md_file}")
                except Exception as e:
                    logger.warning(f"Failed to load command from {md_file}: {e}")
        except Exception as e:
            logger.warning(f"Failed to read commands directory {directory}: {e}")
    
    def expand_slash_command(self, text: str) -> str:
        """
        å±•é–‹ slash æŒ‡ä»¤ã€‚å¦‚æœæ–‡å­—ä»¥ /command é–‹é ­ï¼Œå˜—è©¦æ›¿æ›ç‚ºæŒ‡ä»¤å…§å®¹ã€‚
        æ”¯æ´åƒæ•¸æ›¿æ›ï¼š$ARGUMENTS, $1, $2, ...
        """
        text = text.strip()
        if not text.startswith("/"):
            return text
        
        # åŒ¹é… /command æˆ– /command args...
        match = re.match(r'^/(\S+)(?:\s+(.*))?$', text, re.DOTALL)
        if not match:
            return text
        
        command_id = match.group(1)
        args_text = match.group(2) or ""
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºå·²çŸ¥çš„è‡ªå®šç¾©æŒ‡ä»¤
        if command_id not in self.commands:
            logger.debug(f"Slash command /{command_id} not found in custom commands, passing through")
            return text
        
        template = self.commands[command_id]
        logger.info(f"Expanding slash command: /{command_id}")
        
        # è§£æåƒæ•¸ï¼ˆä»¥ç©ºç™½åˆ†éš”ï¼‰
        args_list = args_text.split() if args_text else []
        
        # æ›¿æ› $ARGUMENTS
        result = template.replace("$ARGUMENTS", args_text)
        
        # æ›¿æ› $1, $2, ... (å¾å¤§åˆ°å°æ›¿æ›ï¼Œé¿å… $10 è¢«ç•¶æˆ $1 + 0)
        for i in range(len(args_list), 0, -1):
            result = result.replace(f"${i}", args_list[i - 1])
        
        # å¦‚æœæ¨¡æ¿æ²’æœ‰ placeholder ä½†æœ‰åƒæ•¸ï¼Œé™„åŠ åƒæ•¸åˆ°å…§å®¹å¾Œé¢
        has_placeholders = "$ARGUMENTS" in template or any(f"${i}" in template for i in range(1, len(args_list) + 1))
        if not has_placeholders and args_text:
            result = f"{result}\n\n{args_text}"
        
        logger.debug(f"Expanded /{command_id} to {len(result)} characters")
        return result

class CommandBuilder:
    def __init__(self, model: str, api_key: str, messages: List[Message], session_id: Optional[str] = None, workspace_dir: Optional[str] = None):
        self.model = model
        self.api_key = api_key
        self.messages = messages
        self.session_id = session_id
        self.workspace_dir = workspace_dir
        self.slash_loader = SlashCommandLoader(workspace_dir)

    def _merge_messages(self) -> str:
        """åˆä½µæ‰€æœ‰å°è©±å…§å®¹æˆä¸€å€‹ Promptï¼Œä¸¦å±•é–‹ slash æŒ‡ä»¤"""
        merged = []
        has_assistant = any(msg.role == "assistant" for msg in self.messages)
        for idx, msg in enumerate(self.messages):
            content = msg.content
            logger.debug(f"Message [{idx}] role={msg.role}, content_length={len(content)}, preview={content[:100]}")
            
            # åªå° user è¨Šæ¯å˜—è©¦å±•é–‹ slash æŒ‡ä»¤
            if msg.role == "user":
                expanded = self.slash_loader.expand_slash_command(content)
                if expanded != content:
                    logger.info(f"Message [{idx}] slash command expanded: {len(content)} -> {len(expanded)} chars")
                content = expanded
            
            if has_assistant:
                content = f"{msg.role.upper()}: {content}"

            merged.append(content)
        
        result = "\n\n".join(merged)
        logger.debug(f"Merged {len(self.messages)} messages into {len(result)} characters")
        return result

    def build(self, stream: bool = False) -> List[str]:
        prompt = self._merge_messages()
        
        cmd = [
            config.CURSOR_BIN,
            "--model", self.model,
            "--api-key", self.api_key,
            "--sandbox", "enabled",
            "--approve-mcps",
            "--force", # "approve-mcps" has a bug. We still need the "force" option to run the MCP tools.
            "--print",
        ]
        
        if self.session_id:
            cmd.extend(["--resume", self.session_id])
        
        if self.workspace_dir:
            cmd.extend(["--workspace", self.workspace_dir])
        
        if stream:
            cmd.extend(["--output-format", "stream-json", "--stream-partial-output"])
        else:
            cmd.extend(["--output-format", "json"])
            
        cmd.append(prompt)
        return cmd

class Executor:
    """è² è²¬åŸ·è¡Œ CLI æŒ‡ä»¤"""
    
    def _format_tool_call_start(self, tool_call: dict, tool_count: int) -> Optional[str]:
        """Format tool call start information for output"""
        logger.debug(f"Tool call: {tool_call}")
        # Handle writeToolCall
        if "writeToolCall" in tool_call:
            args = tool_call["writeToolCall"].get("args", {})
            path = args.get("path", "unknown")
            return f"ğŸ–Šï¸ Tool #{tool_count}: Creating {path}\n "
        
        # Handle readToolCall
        elif "readToolCall" in tool_call:
            args = tool_call["readToolCall"].get("args", {})
            path = args.get("path", "unknown")
            return f"ğŸ“– Tool #{tool_count}: Reading {path}\n "
        
        # Handle mcpToolCall
        elif "mcpToolCall" in tool_call:
            mcp_args = tool_call["mcpToolCall"].get("args", {})
            tool_name = mcp_args.get("name", "unknown")
            provider = mcp_args.get("providerIdentifier", "unknown")
            return f"ğŸ”Œ Tool #{tool_count}: MCP {provider}-{tool_name}\n "
        
        # Handle other/unknown tool calls
        else:
            # Process any tool call by using the first key
            if tool_call:
                key = next(iter(tool_call.keys()))
                args = tool_call[key].get("args", {})
                return f"ğŸ”¨ Tool #{tool_count}: {key} \n "
        
        return None
    
    def _format_tool_call_result(self, tool_call: dict, tool_number: Optional[int] = None) -> Optional[str]:
        """Format tool call result information for output"""
        tool_prefix = f"Tool #{tool_number}: " if tool_number else ""
        
        # Handle writeToolCall result
        if "writeToolCall" in tool_call:
            result = tool_call["writeToolCall"].get("result", {})
            if "success" in result:
                success = result["success"]
                lines = success.get("linesCreated", 0)
                size = success.get("fileSize", 0)
                return f"ğŸ–Šï¸ {tool_prefix}Created {lines} lines ({size} bytes)\n "
            elif "error" in result:
                error_msg = result["error"].get("message", "Unknown error")
                return f"ğŸ–Šï¸ {tool_prefix}Error: {error_msg}\n "
        
        # Handle readToolCall result
        elif "readToolCall" in tool_call:
            result = tool_call["readToolCall"].get("result", {})
            if "success" in result:
                success = result["success"]
                total_lines = success.get("totalLines", 0)
                return f"ğŸ“– {tool_prefix}Read {total_lines} lines\n "
            elif "error" in result:
                error_msg = result["error"].get("message", "Unknown error")
                return f"ğŸ“– {tool_prefix}Error: {error_msg}\n "
        
        # Handle mcpToolCall result
        elif "mcpToolCall" in tool_call:
            result = tool_call["mcpToolCall"].get("result", {})
            if "rejected" in result:
                reason = result["rejected"].get("reason", "Unknown reason")
                return f"ğŸ”Œ {tool_prefix}Rejected: {reason}\n "
            elif "success" in result:
                return f"ğŸ”Œ {tool_prefix}Completed\n "
            elif "error" in result:
                error_msg = result.get("error", {}).get("message", "Unknown error")
                return f"ğŸ”Œ {tool_prefix}Error: {error_msg}\n "
        
        # Handle other/unknown tool calls
        else:
            # Process any tool call by using the first key
            if tool_call:
                key = next(iter(tool_call.keys()))
                result = tool_call[key].get("result", {})
                if "rejected" in result:
                    reason = result["rejected"].get("reason", "Unknown reason")
                    return f"ğŸ”¨ {tool_prefix}Rejected: {reason}\n "
                elif "success" in result:
                    return f"ğŸ”¨ {tool_prefix}Completed\n "
                elif "error" in result:
                    error_msg = result["error"].get("message", "Unknown error")
                    return f"ğŸ”¨ {tool_prefix}Error: {error_msg}\n "
        
        return None
    
    async def run_non_stream(self, cmd: List[str], cwd: Optional[str] = None, timeout: float = 300) -> str:
        """åŸ·è¡ŒæŒ‡ä»¤ï¼Œç›£æ§ stdoutï¼Œæ”¶åˆ°æœ‰æ•ˆ JSON çµæœå¾Œç«‹å³è¿”å›"""
        process = await asyncio.create_subprocess_exec(
            *cmd,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE,
            cwd=cwd,
            limit=1024 * 1024 * 10,  # 10MB
        )
        
        stdout_buffer = b""
        
        async def read_until_json():
            nonlocal stdout_buffer
            # é€å¡Šè®€å– stdout
            while True:
                chunk = await process.stdout.read(4096)
                if not chunk:
                    # stdout é—œé–‰äº†
                    break
                stdout_buffer += chunk
                
                # å˜—è©¦è§£æ JSON - å¦‚æœæˆåŠŸï¼Œè¡¨ç¤ºè¼¸å‡ºå®Œæˆ
                try:
                    data = json.loads(stdout_buffer.decode())
                    # æˆåŠŸè§£æ JSONï¼Œå¯ä»¥ç«‹å³è¿”å›
                    logger.debug("Received valid JSON output, returning immediately")
                    return data.get("result", "")
                except (json.JSONDecodeError, UnicodeDecodeError):
                    # JSON é‚„ä¸å®Œæ•´æˆ– UTF-8 å­—ç¬¦è¢«æˆªæ–·ï¼Œç¹¼çºŒè®€å–
                    continue
            # å¦‚æœæ²’æœ‰æ”¶åˆ°æœ‰æ•ˆ JSONï¼Œè¿”å›åŸå§‹è¼¸å‡º
            return stdout_buffer.decode(errors='replace').strip()
        
        try:
            result = await asyncio.wait_for(read_until_json(), timeout=timeout)
            return result
        except asyncio.TimeoutError:
            logger.warning(f"Process timed out after {timeout}s, terminating...")
            raise RuntimeError(f"CLI execution timed out after {timeout}s")
        finally:
            # æ¸…ç†ï¼šå¦‚æœé€²ç¨‹é‚„åœ¨è·‘ï¼Œçµ‚æ­¢å®ƒ
            if process.returncode is None:
                process.terminate()
                try:
                    await asyncio.wait_for(process.wait(), timeout=2.0)
                except asyncio.TimeoutError:
                    process.kill()
                    await process.wait()

    async def run_stream(self, cmd: List[str], cwd: Optional[str] = None):
        """åŸ·è¡ŒæŒ‡ä»¤ä¸¦ä¸²æµå›å‚³ stdout"""
        logger.debug(f"Starting stream command: {cmd}")
        if cwd:
            logger.debug(f"Working directory: {cwd}")
        process = await asyncio.create_subprocess_exec(
            *cmd,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE,
            cwd=cwd,
            limit=1024 * 1024 * 1, # 1MB
        )
        
        line_count = 0
        tool_count = 0
        call_id_to_tool_number = {}  # Track call_id -> tool_number mapping
        last_full_text = ""
        
        async for line in process.stdout:
            line_str = line.decode().strip()
            if not line_str:
                continue
            
            line_count += 1
            
            try:
                data = json.loads(line_str)
                logger.debug(f"[Stream Line {line_count}] Received JSON type: {data.get('type')}")
                
                # åªè™•ç† assistant é¡å‹çš„ delta
                event_type = data.get("type")
                if event_type == "assistant":
                    if "timestamp_ms" in data:
                        content_list = data.get("message", {}).get("content", [])
                        logger.debug(f"[Stream Line {line_count}] Content list has {len(content_list)} items")
                        
                        # Accumulate all text content from this message
                        full_text = ""
                        for idx, item in enumerate(content_list):
                            if item.get("type") == "text":
                                text = item.get("text", "")
                                full_text += text
                                logger.debug(f"[Stream Line {line_count}] Item {idx}: text length = {len(text)}")
                        
                        if not full_text:
                            continue

                        if full_text == last_full_text:
                            logger.debug(f"[Stream Line {line_count}] Duplicate content detected, skipping")
                            continue

                        if full_text.startswith(last_full_text):
                            delta = full_text[len(last_full_text):]
                            if delta:
                                logger.debug(f"[Stream Line {line_count}] Yielding delta {len(delta)} bytes")
                                yield delta
                        else:
                            # Content reset or out-of-order; yield full chunk
                            logger.debug(f"[Stream Line {line_count}] Content reset detected, yielding {len(full_text)} bytes")
                            yield full_text

                        last_full_text = full_text
                    else:
                        # æ”¶åˆ°æ²’æœ‰ timestamp çš„è¨Šæ¯ï¼Œè¦–ç‚ºçµå°¾ï¼Œåœæ­¢ä¸²æµ
                        logger.debug(f"[Stream Line {line_count}] Received assistant message without timestamp, ending stream")
                        break
                elif event_type == "system":
                    subtype = data.get("subtype")
                    if subtype == "init":
                        model = data.get("model", "unknown")
                        logger.debug(f"[Stream Line {line_count}] System init, model={model}")
                    else:
                        logger.debug(f"[Stream Line {line_count}] System event subtype={subtype}")
                elif event_type == "tool_call":
                    subtype = data.get("subtype")
                    call_id = data.get("call_id")
                    tool_call = data.get("tool_call", {})
                    logger.debug(f"[Stream Line {line_count}] Tool call event subtype={subtype}, call_id={call_id}, keys={list(tool_call.keys())}")
                    
                    # Format and yield tool call information
                    if subtype == "started":
                        tool_count += 1
                        # Remember the mapping from call_id to tool_number
                        if call_id:
                            call_id_to_tool_number[call_id] = tool_count
                        tool_info = self._format_tool_call_start(tool_call, tool_count)
                        if tool_info:
                            yield tool_info
                    elif subtype == "completed":
                        # Look up the tool_number for this call_id
                        tool_number = call_id_to_tool_number.get(call_id) if call_id else None
                        tool_result = self._format_tool_call_result(tool_call, tool_number)
                        if tool_result:
                            yield tool_result
                elif event_type == "result":
                    duration_ms = data.get("duration_ms")
                    logger.debug(f"[Stream Line {line_count}] Result event duration_ms={duration_ms}, ending stream")
                    break
                else:
                    logger.debug(f"[Stream Line {line_count}] Skipping unknown message type={event_type}")
            except json.JSONDecodeError as e:
                # å¦‚æœä¸æ˜¯ JSONï¼Œå¯èƒ½æ˜¯èˆŠç‰ˆæœ¬çš„è¼¸å‡ºæˆ–éŒ¯èª¤è¨Šæ¯
                logger.warning(f"[Stream Line {line_count}] Failed to decode JSON: {e}, line: {line_str[:100]}")
                yield line_str
            
        logger.debug(f"Stream finished after {line_count} lines")
        await process.wait()
        
        if process.returncode != 0:
            stderr = await process.stderr.read()
            logger.error(f"Stream command failed with code {process.returncode}: {stderr.decode()}")
            raise RuntimeError(f"CLI execution failed (code {process.returncode}): {stderr.decode()}")